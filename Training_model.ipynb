{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.utils import Sequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_freq = 101\n",
    "Tx = 1332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    \"\"\"\n",
    "    Function creating the model's graph in Keras.\n",
    "    \n",
    "    Argument:\n",
    "    input_shape -- shape of the model's input data (using Keras conventions)\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "       \n",
    "    # Step 1: CONV layer (≈4 lines)\n",
    "    X = Conv1D(196,15,strides=4)(X_input)                         \n",
    "    X = BatchNormalization()(X)                           \n",
    "    X = Activation('relu')(X)              \n",
    "    X = Dropout(0.8)(X)                      \n",
    "    \n",
    "    # Step 2: First GRU Layer (≈4 lines)\n",
    "    X = GRU(units = 128, return_sequences = True)(X)                              \n",
    "    X = Dropout(0.8)(X)                                \n",
    "    X = BatchNormalization()(X)                                 \n",
    "    \n",
    "    # Step 3: Second GRU Layer (≈4 lines)\n",
    "    X = GRU(units = 128, return_sequences = True)(X)                                \n",
    "    X = Dropout(0.8)(X)                                \n",
    "    X = BatchNormalization()(X)\n",
    "    X = Dropout(0.8)(X)                               \n",
    "    \n",
    "    # Step 4: Time-distributed dense layer (≈1 line)\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1332, 101)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 330, 196)          297136    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 330, 196)          784       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 330, 196)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 330, 196)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 330, 128)          124800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 330, 128)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 330, 128)          512       \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 330, 128)          98688     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 330, 128)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 330, 128)          512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 330, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 330, 1)            129       \n",
      "=================================================================\n",
      "Total params: 522,561\n",
      "Trainable params: 521,657\n",
      "Non-trainable params: 904\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model(input_shape = (Tx, n_freq))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(f\"./_data/x{1}.npy\")\n",
    "y = np.load(f\"./_data/y{1}.npy\")\n",
    "\n",
    "for i in range(2,26):\n",
    "    x_ = np.load(f\"./_data/x{i}.npy\")\n",
    "    y_ = np.load(f\"./_data/y{i}.npy\")\n",
    "    x = np.append(x, x_, axis=0)\n",
    "    y = np.append(y, y_, axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 1332, 101)\n",
      "(2500, 330, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = model\n",
    "checkpointer = ModelCheckpoint(filepath='./model_{}.weights.best.hdf5'.format(network), verbose=1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1674 samples, validate on 826 samples\n",
      "Epoch 1/16\n",
      "1674/1674 [==============================] - 58s 34ms/step - loss: 1.0566 - acc: 0.6451 - val_loss: 0.5345 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53453, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 2/16\n",
      "1674/1674 [==============================] - 36s 21ms/step - loss: 0.7725 - acc: 0.8091 - val_loss: 0.4418 - val_acc: 0.9770\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.53453 to 0.44179, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 3/16\n",
      "1674/1674 [==============================] - 36s 22ms/step - loss: 0.6195 - acc: 0.8423 - val_loss: 0.3304 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44179 to 0.33036, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 4/16\n",
      "1674/1674 [==============================] - 35s 21ms/step - loss: 0.5058 - acc: 0.8731 - val_loss: 0.2139 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.33036 to 0.21394, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 5/16\n",
      "1674/1674 [==============================] - 35s 21ms/step - loss: 0.4065 - acc: 0.8982 - val_loss: 0.1411 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21394 to 0.14106, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 6/16\n",
      "1674/1674 [==============================] - 39s 23ms/step - loss: 0.3301 - acc: 0.9180 - val_loss: 0.0917 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14106 to 0.09169, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 7/16\n",
      "1674/1674 [==============================] - 44s 26ms/step - loss: 0.2738 - acc: 0.9329 - val_loss: 0.0637 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09169 to 0.06370, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 8/16\n",
      "1674/1674 [==============================] - 41s 24ms/step - loss: 0.2375 - acc: 0.9417 - val_loss: 0.0462 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.06370 to 0.04620, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 9/16\n",
      "1674/1674 [==============================] - 40s 24ms/step - loss: 0.2094 - acc: 0.9480 - val_loss: 0.0361 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04620 to 0.03614, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 10/16\n",
      "1674/1674 [==============================] - 42s 25ms/step - loss: 0.1918 - acc: 0.9526 - val_loss: 0.0319 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03614 to 0.03186, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 11/16\n",
      "1674/1674 [==============================] - 40s 24ms/step - loss: 0.1763 - acc: 0.9563 - val_loss: 0.0286 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03186 to 0.02865, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 12/16\n",
      "1674/1674 [==============================] - 35s 21ms/step - loss: 0.1603 - acc: 0.9594 - val_loss: 0.0283 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02865 to 0.02830, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 13/16\n",
      "1674/1674 [==============================] - 35s 21ms/step - loss: 0.1480 - acc: 0.9614 - val_loss: 0.0259 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02830 to 0.02588, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 14/16\n",
      "1674/1674 [==============================] - 35s 21ms/step - loss: 0.1394 - acc: 0.9627 - val_loss: 0.0271 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02588\n",
      "Epoch 15/16\n",
      "1674/1674 [==============================] - 35s 21ms/step - loss: 0.1356 - acc: 0.9631 - val_loss: 0.0249 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02588 to 0.02487, saving model to ./model_<keras.engine.training.Model object at 0x7fbc592777f0>.weights.best.hdf5\n",
      "Epoch 16/16\n",
      "1674/1674 [==============================] - 36s 22ms/step - loss: 0.1312 - acc: 0.9632 - val_loss: 0.0256 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02487\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x, y=y, epochs=16, batch_size=48, validation_split=0.33,callbacks=[checkpointer],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = history.history['val_loss']\n",
    "loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(16),val_loss)\n",
    "plt.plot(range(16),loss)\n",
    "plt.title(\"Loss vs No. of Epochs\")\n",
    "plt.legend([\"validation loss\",\"training loss\"])\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.ylabel('Loss')\n",
    "ax = plt.show()\n",
    "plt.savefig(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
